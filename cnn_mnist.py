# -*- coding: utf-8 -*-
"""CNN_MNist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k_32GlyiWCmHzWvC1T74s9onVyRW_UFB
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import matplotlib.pyplot as plt
import numpy as np
import torchvision
from torch import nn, optim
# nn cung cấp những thứ cần thiết để xây dựng mạng neural, optim cung cấp các thuật toán tối ưu
from torchvision import datasets, transforms
# torchvision cung cấp các bộ dữ liệu và các kiến trúc mô hình cho thị giác máy tính, transforms dùng để biến đổi hình ảnh



batch_size = 32
learning_rate = 0.01
num_epochs = 20

# Load dữ liệu kiểu gì ? dữ liệu có sẵn trong thư viện/dữ liệu đưa từ bên ngoài vào
# Đang load dữ liệu từ thư viện torchvision
'''Các tham số : root: đường dẫn đến nơi dữ liệu được lưu trữ
                 train: nếu là True -> data dùng để train, nếu là False -> data dùng để test
                 download: nếu dữ liệu không có sẵn tại root thì download trên internet
                 transform: chỉ định các tính năng chuyển đổi dữ liệu
                 shuffle: dùng để xáo trộn dữ liệu, nếu là tập train thì luôn có sự xáo trộn để mô hình học tốt, con nếu là tập test thì tắt để đánh giá ổn định'''
train_data = torch.utils.data.DataLoader(
    datasets.MNIST(root="data", train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307, ), (0.3081)),
                   ])),
    batch_size=batch_size,
    shuffle=True
)

val_data = torch.utils.data.DataLoader(
    datasets.MNIST(root="data", train=False, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307, ), (0.3081)),
                   ])),
    batch_size=batch_size,
    shuffle=False
)

def imshow(img, mean, std):
  img = img / std + mean
  npimg = img.numpy()
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  plt.show()

dataiter = iter(train_data)
images, labels = next(dataiter)
imshow(torchvision.utils.make_grid(images), 0.1307, 0.3081)
print(labels)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Các tham số chính trong nn.Conv2d :
                                    # in_channels: số kênh đầu vào
                                    # out_channels: số kênh đầu ra
                                    # kernel_size: kích thước của nhân của lớp tích chập
                                    # stride: cửa sổ trượt
                                    # padding: lớp đệm được thêm vào 4 phía của đầu vào
                                    # dilation: khoảng cách giữa các phần tử kernel

class ModelCNNv2(nn.Module):
  def __init__(self, num_classes=10):
    super(ModelCNNv2, self).__init__()
    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1) # padding = "same" => padding = 1
    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
    self.conv2 = nn.Conv2d(16, 32, kernel_size=1, stride=1, padding=1)
    self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)
    self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)

    self.fc = nn.Linear(32*4*4, num_classes)

  def forward(self, x):
    x = self.conv1(x)   # (batch, 16, H, W)
    x = self.pool1(x)   # (batch, 16, H/2, W/2)
    x = self.conv2(x)   # (batch, 32, H/2, W/2)
    x = self.pool2(x)   # (batch, 32, H/4, W/4)
    x = self.conv3(x)   # (batch, 32, H/8, W/8)
    x = x.view(x.size(0), -1)
    x = self.fc(x)

    return x

class ModelCNN(nn.Module):
  def __init__(self, num_classes=10):
    super(ModelCNN,self).__init__()
    self.conv1 = nn.Sequential(
        nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )

    self.fc = nn.Linear(14*14*32, num_classes)

  def forward(self, x):
    out = self.conv1(x)
    out = out.view(out.size(0), -1)
    out = self.fc(out)

    return out

model1 = ModelCNN().to(device)
model2 = ModelCNNv2().to(device)

criterion = nn.CrossEntropyLoss()

optimizer1 = optim.SGD(model1.parameters(), lr=learning_rate)
optimizer2 = optim.SGD(model2.parameters(), lr=learning_rate)

num_steps = len(train_data)

for epoch in range(num_epochs):
  model2.train()
  total_loss = 0

  for i, (images, labels) in enumerate(train_data):
    images, labels = images.to(device), labels.to(device)
    optimizer2.zero_grad()
    outputs = model2(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer2.step()

    total_loss += loss.item()

    if (i+1)%100 == 0:
      print("Epoch {}/{} - Step: {}/{} - Loss: {:.4f}".format(epoch+1, num_epochs, i, num_steps, total_loss/(i+1)))

model2.eval()
val_losses = 0

with torch.no_grad():
  correct = 0
  total = 0
  for _, (images, labels) in enumerate(val_data):
    images, labels = images.to(device), labels.to(device)
    outputs = model2(images)
    _, predicted = torch.max(outputs.data, 1)
    loss = criterion(outputs, labels)
    val_losses += loss.item()
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

  print("Epoch {} - Accuracy: {} - Validation Loss: {:.4f}".format(epoch+1, correct/total, val_losses/(len(val_data))))

